# HW1 Deep Learning Theory #

注意！因初始值為 randomized，結果可能和 report 中稍有不同。

### HW 1-1 Shallow vs Deep

For 1-1-1 Fit a Function and bonus
<pre>cd 1-1-1/
bash 1-1-1.sh</pre>

For 1-1-2 Train on MNIST/CIFAR10
<pre>cd 1-1-2/
bash 1-1-2.sh</pre>

For 1-1-2 Bonus
<pre>cd 1-1-b/
bash 1-1-b.sh</pre>

### HW 1-2 Optimization

For 1-2-1 Visualize the Optimization Process
<pre>cd 1-2-1/
bash 1-2-1.sh</pre>

For 1-2-2 Observe Gradient Norm
<pre>cd 1-2-2/
bash 1-2-2.sh</pre>

For 1-2-3 When Gradient is Almost Zero
<pre>cd 1-2-3/
bash 1-2-3.sh</pre>

For 1-2 Bonus
<pre>cd 1-2-b/
bash 1-2-b.sh</pre>

### HW 1-3 Generalization

For 1-3-1 Fit Random Labels
<pre>cd 1-3-1/
bash 1-3-1.sh</pre>

For 1-3-2 Number of Parameters
<pre>cd 1-3-2/
bash 1-3-2.sh</pre>

For 1-3-3 Flatness vs Generalization
<pre>cd 1-3-3/
bash 1-3-3.sh</pre>

For 1-3 Bonus (Running this script may need a GPU with at least 8GB of VRAM and 10GB of free disk space!)
<pre>cd 1-3-b/
bash 1-3-b.sh</pre>
